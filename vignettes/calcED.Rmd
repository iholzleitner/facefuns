---
title: "Calculate similarity of faces"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Calculate similarity of faces}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**WORK IN PROGRESS/needs rewriting after function changes**

This tutorial will explain how to calculate facial (dis)similarity in a set of 2D faces. We will calculate the Euclidean distance between Procrustes-aligned landmark templates, as well as the Euclidean distance in face space (i.e. principal component space), and compare these two measures.

```{r setup, message=FALSE}
library(facefuns)
library(geomorph)
```

## Read and prepare data

```{r}
path_to_tem <- system.file("extdata", "tem", package="facefuns")
remove_points <- c(45:50, 100:104, 116:125, 146:158, 159:164, 165:170, 171:174, 175:179, 184:185)

data <- read_lmdata(lmdata = path_to_tem,
                       remove_points = remove_points,
                       plot = FALSE)

shapedata <- quickstart(data = data,
                         rotate = "rotateC",
                         plot_sample = TRUE,
                         pc_criterion = "broken_stick")
```


## Calculate facial similarity from landmark templates

We will use `facefuns::calcED` to calculate similarity. `calcED` requires two arguments:

1. Landmark coordinates in a matrix format

2. A table specifying for which pairs of faces you would like to calculate similarity

### Create landmark matrix

Currently, our landmark templates are stored in a three-dimensional array: a list of *n* matrices of dimensions *p* x *k*

* _**p**_ The number of landmarks, here 132
* _**k**_ The number of landmark dimensions, here 2
* _**n**_ The number of faces, here 102

```{r}
str(shapedata$array)
```

We will use `facefuns::convertArrayToMatrix` to convert our array into a matrix with *n* rows and *p* x *k* columns.

```{r}
data_matrix <- convertArrayToMatrix(shapedata$array)
str(data_matrix)
```

### Create list of faces

Most times, you will already have a list of face pairs for which you want to calculate similarity. 

For this example, we will calculate the similarity between *all* possible combinations of face pairs in our data set.

We start by assigning all face IDs in our sample to a variable ...

```{r}
face_names <- dimnames(shapedata$array)[[3]]
```

... and then create a list of all possible combinations

```{r}
pairs <- expand.grid(A = face_names,
                     B = face_names)
```

### `calcED`

We now have everything we need to run our function

```{r}
sim_table <- calcED(coords_matrix = data_matrix,
                    pairs_table = pairs)

head(sim_table)
```
Let's display our data in a wide format and round the values. It is a rather big table, so we will only print a small subset

```{r}
sim_table %>%
  dplyr::mutate(EuclideanDistance = round(EuclideanDistance, 2)) %>%
  tidyr::spread(B, EuclideanDistance) %>%
  dplyr::select(1:10) %>%
  dplyr::slice(1:9)
```

## Calculate facial similarity in face space

Run PCA, extract scores, same as above.

Comparing the two: should be extremely highly correlated (or at least they are in 3D!); the point being that it doesn't make much difference which one you go for (well, we'll see).

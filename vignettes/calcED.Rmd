---
title: "Calculate similarity of faces"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Calculate similarity of faces}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

**WORK IN PROGRESS**

This tutorial will explain how to calculate facial (dis)similarity in a set of 2D faces. We will calculate the Euclidean distance between Procrustes-aligned landmark templates, as well as the Euclidean distance in face space (i.e. principal component space), and compare the two.

```{r setup, message=FALSE}
library(facefuns)
library(geomorph)
```

## Read and prepare data

```{r}
path_to_tem <- system.file("extdata", "tem", package="facefuns")
remove_points <- c(45:50, 100:104, 116:125, 146:158, 159:164, 165:170, 171:174, 175:179, 184:185)

data <- read_lmdata(lmdata = path_to_tem,
                       remove_points = remove_points,
                       plot = FALSE)

shapedata <- quickstart(data = data,
                         plot_sample = TRUE,
                         pc_criterion = "broken_stick")
```


## Calculate facial similarity

### From landmarks

We will use `facefuns::calcED` to calculate similarity. `calcED` requires two arguments:

1. Landmark coordinates in a matrix format

2. A table specifying for which pairs of faces you would like to calculate similarity

### Create landmark matrix

Currently, our landmark templates are stored in a three-dimensional array: a list of *n* matrices of dimensions *p* x *k*

* _**p**_ The number of landmarks, here 132
* _**k**_ The number of landmark dimensions, here 2
* _**n**_ The number of faces, here 102

```{r}
str(shapedata$array)
```

We will use `facefuns::convertArrayToMatrix` to convert our array into a matrix with *n* rows and *p* x *k* columns.

```{r}
data_matrix <- convertArrayToMatrix(shapedata$array)
str(data_matrix)
```

### Create list of faces

Most times, you will already have a list of face pairs for which you want to calculate similarity. 

For this example, we will calculate the similarity between *all* possible combinations of face pairs in our data set.

We start by assigning all face IDs in our sample to a variable ...

```{r}
face_names <- dimnames(shapedata$array)[[3]]
```

... and then create a list of all possible combinations

```{r}
pairs <- expand.grid(A = face_names,
                     B = face_names)
```

### `calcED`

We now have everything we need to run our function

```{r}
sim_table <- calcED(coords_matrix = data_matrix,
                    pairs_table = pairs)

head(sim_table)
```
Let's display our data in a wide format and round the values. It is a rather big table, so we will only print a small subset

```{r}
sim_table %>%
  dplyr::mutate(EuclideanDistance = round(EuclideanDistance, 2)) %>%
  tidyr::spread(B, EuclideanDistance) %>%
  dplyr::select(1:10) %>%
  dplyr::slice(1:9)
```

### In face space

[*Run PCA, extract scores, same as above. Compare the two.*]

## Averageness

Averageness can be quantified as distinctivenss from the sample average. For each face, we will calculate the Euclidean distance to the sample average, and then reverse scores, so higher scores mean "more average".

You could use `calcED`, but this will require a wee bit of data wrangling: you will need to attach the average template to the array holding the aligned templates, then convert this new array to a matrix and finally you might also want to reverse the distinctiveness scores, so higher scores mean "more average'. `calcAVG` does all of that! It only takes one argument - a `quickstart` object:

```{r}
distinctiveness <- calcAVG(shapedata)

head(distinctiveness)
```
